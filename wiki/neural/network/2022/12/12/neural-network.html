<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Neural Network</h1><p class="page-description">Wikibot Neural Network.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-12-12T00:00:00-06:00" itemprop="datePublished">
        Dec 12, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/bottoni/categories/#wiki">wiki</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#neural">neural</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#network">network</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#one-liner-definition">One Liner Definition</a></li>
<li class="toc-entry toc-h2"><a href="#motivation">Motivation</a></li>
<li class="toc-entry toc-h2"><a href="#implementation">Implementation</a></li>
<li class="toc-entry toc-h2"><a href="#take-away">Take Away</a>
<ul>
<li class="toc-entry toc-h3"><a href="#further-work">Further Work</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul><h2 id="one-liner-definition">
<a class="anchor" href="#one-liner-definition" aria-hidden="true"><span class="octicon octicon-link"></span></a>One Liner Definition</h2>
<p>Neural Network is a mathematical function.</p>

<p>This mathematical function is based on inputs and parameters.</p>

<p>Inputs and parameters are multiplied and added them up. Negative values are set to zero.</p>

<p>These operations are repeated untill the error of prediction is minimized.</p>

<h2 id="motivation">
<a class="anchor" href="#motivation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motivation</h2>

<p>These 3 simple steps are the foundation of any deep learning model.</p>

<p>Implicitally they touch most important parts of NN:</p>
<ol>
  <li>Inputs and parameters are multiplied and added them up =&gt; <a href="">Matrix multiplication</a>;</li>
  <li>Negative values are set to zero =&gt; <a href="">Rectified Linear function</a>;</li>
  <li>Operations repeated untill error of prediction is minimized =&gt; <a href="">Gradient descent</a> on <a href="">Loss function</a>.</li>
</ol>

<p>The most complex deep learning model is built on these foundamentals. Deeply understanding them will help to breaking every complex model out.</p>

<h2 id="implementation">
<a class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span>  <span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quad</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">c</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mult</span><span class="p">,</span> <span class="n">add</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mult</span><span class="p">))</span> <span class="o">+</span> <span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">add</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">20</span><span class="p">)[:,</span><span class="bp">None</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="k">def</span> <span class="nf">mk_quad</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span> <span class="k">return</span> <span class="n">partial</span><span class="p">(</span><span class="n">quad</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mae</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">pred</span><span class="o">-</span><span class="n">actual</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quad_mae</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">mk_quad</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">abc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">abc</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">()</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">quad_mae</span><span class="p">(</span><span class="n">abc</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">quad_mae</span><span class="p">(</span><span class="n">abc</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="n">abc</span> <span class="o">-=</span> <span class="n">abc</span><span class="p">.</span><span class="n">grad</span><span class="o">*</span><span class="mf">0.01</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'step=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">; loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>step=0; loss=2.42
step=1; loss=2.40
step=2; loss=2.36
step=3; loss=2.30
step=4; loss=2.21
step=5; loss=2.11
step=6; loss=1.98
step=7; loss=1.85
step=8; loss=1.72
step=9; loss=1.58
</code></pre></div></div>

<h2 id="take-away">
<a class="anchor" href="#take-away" aria-hidden="true"><span class="octicon octicon-link"></span></a>Take Away</h2>

<ol>
  <li>
<a href="">Matrix multiplication</a> is the key to quickly calculate multuplication and addition of inputs and parameters.</li>
  <li>
<a href="">Gradient descent</a> is the tool used to understand how to minimize the loss function, since loss function composed by parameters <code class="language-plaintext highlighter-rouge">abc</code>.</li>
  <li>
<a href="">Rectified Linear function</a>, known as <a href="">ReLU</a>, is a linear function which takes input and the ouput is equals to the input. If the input is negative the output is zero. Itâ€™s defined as: $f(x) = max(0, x)$</li>
</ol>

<h3 id="further-work">
<a class="anchor" href="#further-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Further Work</h3>
<ol class="task-list">
  <li>Ankify:
    <ul class="task-list">
      <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Matrix multiplication</li>
      <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Gradient descent</li>
      <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>ReLU</li>
      <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>End to end GD which every DL model is based on</li>
    </ul>
  </li>
  <li class="task-list-item">
<input type="checkbox" class="task-list-item-checkbox" disabled>Develop a Neural Network from scratch</li>
</ol>

<hr>
<h2 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h2>
<ul>
  <li><a href="https://course.fast.ai/Lessons/lesson3.html">Neural net foundations - Jeremy Howard, 2022</a></li>
  <li><a href="https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work">How does a neural net really work? - Jeremy Howard, 2022</a></li>
  <li>Chatting with <a href="https://chat.openai.com/">ChatGPT</a>
</li>
</ul>

  </div><a class="u-url" href="/bottoni/wiki/neural/network/2022/12/12/neural-network.html" hidden></a>
</article>

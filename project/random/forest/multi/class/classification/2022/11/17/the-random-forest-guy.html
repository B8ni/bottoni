<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Random Forest Guy | frabot</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="The Random Forest Guy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Aluminium Scrap Box Classification." />
<meta property="og:description" content="Aluminium Scrap Box Classification." />
<link rel="canonical" href="https://b8ni.github.io/bottoni/project/random/forest/multi/class/classification/2022/11/17/the-random-forest-guy.html" />
<meta property="og:url" content="https://b8ni.github.io/bottoni/project/random/forest/multi/class/classification/2022/11/17/the-random-forest-guy.html" />
<meta property="og:site_name" content="frabot" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-11-17T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Random Forest Guy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-11-17T00:00:00-06:00","datePublished":"2022-11-17T00:00:00-06:00","description":"Aluminium Scrap Box Classification.","headline":"The Random Forest Guy","mainEntityOfPage":{"@type":"WebPage","@id":"https://b8ni.github.io/bottoni/project/random/forest/multi/class/classification/2022/11/17/the-random-forest-guy.html"},"url":"https://b8ni.github.io/bottoni/project/random/forest/multi/class/classification/2022/11/17/the-random-forest-guy.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/bottoni/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://b8ni.github.io/bottoni/feed.xml" title="frabot" /><link rel="shortcut icon" type="image/x-icon" href="/bottoni/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/bottoni/">frabot</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/bottoni/about/">About Me</a><a class="page-link" href="/bottoni/search/">Search</a><a class="page-link" href="/bottoni/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The Random Forest Guy</h1><p class="page-description">Aluminium Scrap Box Classification.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-11-17T00:00:00-06:00" itemprop="datePublished">
        Nov 17, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/bottoni/categories/#project">project</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#random">random</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#forest">forest</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#multi">multi</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#class">class</a>
        &nbsp;
      
        <a class="category-tags-link" href="/bottoni/categories/#classification">classification</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#scrap-box-dataset">Scrap Box Dataset</a>
<ul>
<li class="toc-entry toc-h3"><a href="#the-problem">The Problem</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#explore-the-dataset">Explore the Dataset</a></li>
<li class="toc-entry toc-h2"><a href="#data-preprocessing">Data Preprocessing</a>
<ul>
<li class="toc-entry toc-h3"><a href="#roc-curve">ROC Curve</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#feature-selection">Feature Selection</a>
<ul>
<li class="toc-entry toc-h3"><a href="#feature-importances">Feature Importances</a></li>
<li class="toc-entry toc-h3"><a href="#features-correlation">Features Correlation</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#baseline-result">Baseline Result</a>
<ul>
<li class="toc-entry toc-h3"><a href="#out-of-domain-data">Out of Domain Data</a></li>
<li class="toc-entry toc-h3"><a href="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#conclusion">Conclusion</a></li>
<li class="toc-entry toc-h2"><a href="#further-work">Further Work</a></li>
</ul><h2 id="scrap-box-dataset">
<a class="anchor" href="#scrap-box-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Scrap Box Dataset</h2>

<p>Days passed from my <a href="https://b8ni.github.io/bottoni/fastai/2022/10/26/aluminium-scraps-box-weight-random-forest-post.html">first Random Forest practical experiment</a>, where I was attempting to predict the weight of an Aluminium Scarp Box.</p>

<p>Spending days going deeper on Random Forest, here you can find a revisioned and hope improved version of the <a href="https://b8ni.github.io/bottoni/fastai/2022/10/26/aluminium-scraps-box-weight-random-forest-post.html">previous one post</a>.</p>

<p><a href="https://youtu.be/yrtAoBr3iuQ?t=144">Short learning cycle</a> suggested me, gradually, what’s matter the most.</p>

<p>Figure out the metrics <em>properly</em>.</p>

<p>Same tip and trick came from <a href="https://github.com/abhishekkrthakur/approachingalmost/blob/master/AAAMLP.pdf">Thakur book</a> where he underlines, before any kind of splitting: understand the data and implement the right metric.</p>

<p><a href="">Target drives metric</a>, therefore undestanding deeply the target will return the right metric.</p>

<h3 id="the-problem">
<a class="anchor" href="#the-problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Problem</h3>

<p>Initially the problem to solve included <code class="language-plaintext highlighter-rouge">681</code> classes. Now I’ve kept only the <code class="language-plaintext highlighter-rouge">11</code> most common.</p>

<p><a href="https://b8ni.github.io/bottoni/fastai/2022/10/26/aluminium-scraps-box-weight-random-forest-post.html">Previously</a> I was using the wrong metric, today I switched to <a href="">AUC ROC</a> metric where it’s mainly used on multi class classification problem.</p>

<p>So, but what’s the target? A multi class classification problem with imbalanced data. It took me a while but worth it.</p>

<p>Wait, imbalanced what? I don’t know yet. Let’s dig into unbalanced data another day.</p>

<h2 id="explore-the-dataset">
<a class="anchor" href="#explore-the-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Explore the Dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"scraps/scrap_202210181239.csv"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">"tare_weight"</span><span class="p">].</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">"tare_weight"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">head</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">top_classes</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"tare_weight"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">head</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">top_classes</span><span class="p">.</span><span class="nb">sum</span><span class="p">())</span><span class="o">/</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span><span class="mi">100</span>
</code></pre></div></div>

<p>In my case I want to reduce the target spectrum. From <code class="language-plaintext highlighter-rouge">681</code> classes to <code class="language-plaintext highlighter-rouge">11</code> classes. This target reduction impacts the dataset by <code class="language-plaintext highlighter-rouge">4.47%</code> of size. <code class="language-plaintext highlighter-rouge">670</code> classes are the result of <strong>inappropriate software usage.</strong> I’m pretty confident the current inserts are happening mostly right.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">top_classes</span><span class="p">[</span><span class="s">"top_classes"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_classes</span><span class="p">.</span><span class="n">index</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'tare_weight'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">top_classes</span><span class="p">[</span><span class="s">"top_classes"</span><span class="p">])]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">82388</span> <span class="o">-</span> <span class="mi">78708</span>
</code></pre></div></div>

<p>Removed <code class="language-plaintext highlighter-rouge">3680</code> rows which meet the <code class="language-plaintext highlighter-rouge">670</code> surplus classes: a bit cut for a big up.</p>

<p>Let’s see features and target correlation with <code class="language-plaintext highlighter-rouge">pairplot</code> method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="c1"># df_2 = df_2[df_2["weight"] &lt;= 3500]
</span><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">[:</span><span class="mi">50</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s">"tare_weight"</span><span class="p">)</span>
</code></pre></div></div>

<p>I don’t see any strong linear correlation (except fews which are duplicated features). It suggests Random Forest, thanks to its ability to work <a href="https://hal.archives-ouvertes.fr/hal-03723551v2/document">uninformative features</a>, would take advantage of the dataset form.</p>

<h2 id="data-preprocessing">
<a class="anchor" href="#data-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Preprocessing</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="n">Categorify</span><span class="p">,</span> <span class="n">FillMissing</span><span class="p">,</span> <span class="n">cont_cat_split</span><span class="p">,</span> <span class="n">RandomSplitter</span>

<span class="n">dep</span> <span class="o">=</span> <span class="s">"tare_weight"</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">"net_weight"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">procs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Categorify</span><span class="p">,</span> <span class="n">FillMissing</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">"max_tickness.1"</span><span class="p">:</span> <span class="s">"article_max_tickness"</span><span class="p">,</span>
                        <span class="s">"min_tickness.1"</span><span class="p">:</span> <span class="s">"article_min_tickness"</span><span class="p">,</span>
                        <span class="s">"max_tickness"</span><span class="p">:</span> <span class="s">"alloy_max_tickness"</span><span class="p">,</span>
                        <span class="s">"min_tickness"</span><span class="p">:</span> <span class="s">"alloy_min_tickness"</span><span class="p">,</span>
                        <span class="s">"name"</span><span class="p">:</span> <span class="s">"location_name"</span><span class="p">})</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cont</span><span class="p">,</span><span class="n">cat</span> <span class="o">=</span> <span class="n">cont_cat_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dep_var</span><span class="o">=</span><span class="n">dep</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">splits</span> <span class="o">=</span> <span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="n">TabularPandas</span> 
<span class="n">to</span> <span class="o">=</span> <span class="n">TabularPandas</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">procs</span><span class="p">,</span> <span class="n">cat</span><span class="p">,</span> <span class="n">cont</span><span class="p">,</span> 
    <span class="n">y_names</span><span class="o">=</span><span class="n">dep</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">to</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">xs</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">to</span><span class="p">.</span><span class="n">train</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">to</span><span class="p">.</span><span class="n">valid</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="n">save_pickle</span>
<span class="n">save_pickle</span><span class="p">(</span><span class="s">'to.pkl'</span><span class="p">,</span><span class="n">to</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="n">load_pickle</span>
<span class="n">to</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'to.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">to</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">xs</span><span class="p">,</span><span class="n">to</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">y</span>
<span class="n">valid_xs</span><span class="p">,</span><span class="n">valid_y</span> <span class="o">=</span> <span class="n">to</span><span class="p">.</span><span class="n">valid</span><span class="p">.</span><span class="n">xs</span><span class="p">,</span><span class="n">to</span><span class="p">.</span><span class="n">valid</span><span class="p">.</span><span class="n">y</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.multiclass</span> <span class="kn">import</span> <span class="n">OneVsRestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ovr_rf</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
       <span class="n">max_features</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
        <span class="n">max_features</span><span class="o">=</span><span class="n">max_features</span><span class="p">,</span>
        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)).</span><span class="n">fit</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<p>Here I’ve simply re-adapted a <a href="https://course.fast.ai/Lessons/lesson6.html">Jeremy</a> <a href="https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb">function</a> to work with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html">One-Versus-Rest pipeline</a>. I’m improving my buzzy worlds man!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span>  <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_prob</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_xs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_prob</span>
</code></pre></div></div>

<p>Actually I’m not using the classic <code class="language-plaintext highlighter-rouge">predict()</code> method. <code class="language-plaintext highlighter-rouge">pred_prob</code> is an array - generated by <code class="language-plaintext highlighter-rouge">predict_proba()</code> method - which contains classes probabilities. See also <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html?highlight=onevsrest+predict_proba#sklearn.multiclass.OneVsRestClassifier.predict_proba">sklearn</a> <a href="https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b6/sklearn/multiclass.py#L450">source code</a>.</p>

<h3 id="roc-curve">
<a class="anchor" href="#roc-curve" aria-hidden="true"><span class="octicon octicon-link"></span></a>ROC Curve</h3>

<p>Now it’s time to analyze our performance with a different metric: AUC ROC.</p>

<p>First <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?highlight=labelencoder#sklearn.preprocessing.LabelEncoder">encoding</a> all classes then <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.label_binarize.html?highlight=label_binarize#sklearn.preprocessing.label_binarize">binirize</a> and finally plot them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Lets encode target labels (y) with values between 0 and n_classes-1.
#We will use the LabelEncoder to do this. 
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="n">label_encoder</span><span class="o">=</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">label_encoder</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">valid_y</span><span class="p">)</span>
<span class="n">transfomerd_valid_y</span><span class="o">=</span><span class="n">label_encoder</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">valid_y</span><span class="p">)</span>
<span class="n">classes</span><span class="o">=</span><span class="n">label_encoder</span><span class="p">.</span><span class="n">classes_</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>
<span class="c1">#binarize the y_values
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">y_test_binarized</span><span class="o">=</span><span class="n">label_binarize</span><span class="p">(</span><span class="n">valid_y</span><span class="p">,</span><span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">valid_y</span><span class="p">))</span>

<span class="c1"># roc curve for classes
</span><span class="n">fpr</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">tpr</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">thresh</span> <span class="o">=</span><span class="p">{}</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="n">n_class</span> <span class="o">=</span> <span class="n">classes</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_class</span><span class="p">):</span>    
    <span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">thresh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_binarized</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">pred_prob</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
    <span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
    <span class="c1"># plotting    
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> 
             <span class="n">label</span><span class="o">=</span><span class="s">'%s vs Rest (AUC=%0.2f)'</span><span class="o">%</span><span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s">'b--'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Multiclass ROC curve'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">avg_roc_auc</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>
<span class="n">avg_roc_auc</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>An average of <code class="language-plaintext highlighter-rouge">94%</code> of being right is really good. Only <code class="language-plaintext highlighter-rouge">750</code> box is mainly miss-classified, with a <code class="language-plaintext highlighter-rouge">83%</code>.</p>

<h2 id="feature-selection">
<a class="anchor" href="#feature-selection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feature Selection</h2>

<p>Feature selection starts from <code class="language-plaintext highlighter-rouge">feature_importances_</code>. I’ve adapted <a href="https://course.fast.ai/Lessons/lesson6.html">Jeremy</a> <a href="https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb">method</a> to work with multi class model.</p>

<h3 id="feature-importances">
<a class="anchor" href="#feature-importances" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feature Importances</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rf_feat_importance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'cols'</span><span class="p">:</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="s">'imp'</span><span class="p">:</span><span class="n">m</span><span class="p">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">feature_importances_</span><span class="p">}</span>
                       <span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'imp'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>Every class have its own feature importances so I have to compress everything in array and remove the last one. I’ve implemented a simple <code class="language-plaintext highlighter-rouge">concat</code> and <code class="language-plaintext highlighter-rouge">mean</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_all</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"tare_weight"</span><span class="p">].</span><span class="n">nunique</span><span class="p">()):</span>
    <span class="n">df_all</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_all</span><span class="p">,</span> <span class="n">rf_feat_importance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">i</span><span class="p">)])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">[</span><span class="s">"cols"</span><span class="p">].</span><span class="n">sort_index</span><span class="p">().</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_all</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">df_all</span><span class="p">.</span><span class="n">index</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_all</span><span class="p">[</span><span class="s">"cols"</span><span class="p">]</span> <span class="o">=</span> <span class="n">cols</span>
<span class="n">df_all</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'imp'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally plotting averaged feature importances of the whole classes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_fi</span><span class="p">(</span><span class="n">fi</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">fi</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="s">'cols'</span><span class="p">,</span> <span class="s">'imp'</span><span class="p">,</span> <span class="s">'barh'</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">plot_fi</span><span class="p">(</span><span class="n">df_all</span><span class="p">[:</span><span class="mi">30</span><span class="p">]);</span>
</code></pre></div></div>

<p>Let’s remove less significant ones.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_all</span><span class="p">[</span><span class="n">df_all</span><span class="p">[</span><span class="s">"imp"</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.002</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fi</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">[</span><span class="n">df_all</span><span class="p">[</span><span class="s">"imp"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.002</span><span class="p">]</span>

<span class="n">filtered_xs</span> <span class="o">=</span> <span class="n">xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">fi</span><span class="p">[</span><span class="s">"cols"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">filtered_valid_xs</span> <span class="o">=</span> <span class="n">valid_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">fi</span><span class="p">[</span><span class="s">"cols"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_xs</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">filtered_valid_xs</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_prob</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">filtered_valid_xs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">roc_plot</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="n">y_test_binarized</span><span class="o">=</span><span class="n">label_binarize</span><span class="p">(</span><span class="n">valid_y</span><span class="p">,</span><span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">valid_y</span><span class="p">))</span>

    <span class="c1"># roc curve for classes
</span>    <span class="n">fpr</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">tpr</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">thresh</span> <span class="o">=</span><span class="p">{}</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="n">n_class</span> <span class="o">=</span> <span class="n">classes</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_class</span><span class="p">):</span>    
        <span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">thresh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test_binarized</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">pred_prob</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
        <span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c1"># plotting    
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> 
                 <span class="n">label</span><span class="o">=</span><span class="s">'%s vs Rest (AUC=%0.2f)'</span><span class="o">%</span><span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">roc_auc</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>


    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s">'b--'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.05</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Multiclass ROC curve'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive rate'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">roc_plot</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">roc_auc_classes</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">)</span>
</code></pre></div></div>

<p>With just removing the less important ones, the model has improved by few decimals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">fastai.tabular.all</span> <span class="kn">import</span> <span class="n">save_pickle</span>
<span class="n">save_pickle</span><span class="p">(</span><span class="s">'filtered_xs.pkl'</span><span class="p">,</span><span class="n">filtered_xs</span><span class="p">)</span>
<span class="n">save_pickle</span><span class="p">(</span><span class="s">'filtered_valid_xs.pkl'</span><span class="p">,</span><span class="n">filtered_valid_xs</span><span class="p">)</span>
<span class="n">filtered_xs</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'filtered_xs.pkl'</span><span class="p">)</span>
<span class="n">filtered_valid_xs</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'filtered_valid_xs.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="features-correlation">
<a class="anchor" href="#features-correlation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Features Correlation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sn</span>

<span class="n">xs_corr</span> <span class="o">=</span> <span class="n">filtered_xs</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">compressed_xs</span> <span class="o">=</span> <span class="n">xs_corr</span><span class="p">[((</span><span class="n">xs_corr</span> <span class="o">&gt;=</span> <span class="p">.</span><span class="mi">5</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">xs_corr</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="p">.</span><span class="mi">5</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xs_corr</span> <span class="o">!=</span><span class="mf">1.000</span><span class="p">)]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sn</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">compressed_xs</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"Reds"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">corrFilter</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="n">xCorr</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
    <span class="n">xFiltered</span> <span class="o">=</span> <span class="n">xCorr</span><span class="p">[((</span><span class="n">xCorr</span> <span class="o">&gt;=</span> <span class="n">bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">xCorr</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">bound</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">xCorr</span> <span class="o">!=</span><span class="mf">1.000</span><span class="p">)]</span>
    <span class="n">xFlattened</span> <span class="o">=</span> <span class="n">xFiltered</span><span class="p">.</span><span class="n">unstack</span><span class="p">().</span><span class="n">sort_values</span><span class="p">().</span><span class="n">drop_duplicates</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">xFlattened</span>

<span class="n">corrFilter</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="p">.</span><span class="mi">65</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">oob_estimators</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">m</span><span class="p">.</span><span class="n">estimators_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">oob_score_</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"tare_weight"</span><span class="p">].</span><span class="n">nunique</span><span class="p">())]</span>
</code></pre></div></div>

<p>Since I’m working with a dataset with <code class="language-plaintext highlighter-rouge">11</code> classes, it’s essential to evaluate for each class relative Out-of-Bag score. So the goal is to remove closely correlated features which keep stagnant or improve the OOB score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oob_estimators</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"timestamp"</span><span class="p">,</span> <span class="s">"slim_alloy"</span><span class="p">,</span> <span class="s">"id_alloy"</span><span class="p">,</span> <span class="s">"pairing_alloy"</span><span class="p">,</span>
           <span class="s">"international_alloy"</span><span class="p">,</span> <span class="s">"id_user"</span><span class="p">,</span> <span class="s">"address"</span><span class="p">,</span>
           <span class="s">"location_name"</span><span class="p">,</span> <span class="s">"article_min_tickness"</span><span class="p">,</span> <span class="s">"article_max_tickness_na"</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="n">c</span><span class="p">:</span><span class="n">oob_estimators</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">to_drop</span><span class="p">}</span>
</code></pre></div></div>

<p>The features belongs to <code class="language-plaintext highlighter-rouge">to_drop</code> list with an average of <code class="language-plaintext highlighter-rouge">OOB</code> score higher, will be dropped.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"pairing_alloy"</span><span class="p">,</span> <span class="s">"id_alloy"</span><span class="p">,</span>
           <span class="s">"article_max_tickness_na"</span><span class="p">,</span> <span class="s">"location_name"</span><span class="p">,</span> <span class="s">"article_max_tickness_na"</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_xs</span> <span class="o">=</span> <span class="n">filtered_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">filtered_valid_xs</span> <span class="o">=</span> <span class="n">filtered_valid_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_valid_xs</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">filtered_xs</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_prob</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">filtered_valid_xs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">roc_plot</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">)</span>
</code></pre></div></div>

<p>Obtaining <code class="language-plaintext highlighter-rouge">94.5%</code> <code class="language-plaintext highlighter-rouge">AUC ROC</code> score while keeping <code class="language-plaintext highlighter-rouge">OOB</code> score higher is a good achievement. Breakpoint saved.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">save_pickle</span><span class="p">(</span><span class="s">'filtered_xs.pkl'</span><span class="p">,</span><span class="n">filtered_xs</span><span class="p">)</span>
<span class="n">save_pickle</span><span class="p">(</span><span class="s">'filtered_valid_xs.pkl'</span><span class="p">,</span><span class="n">filtered_valid_xs</span><span class="p">)</span>
<span class="n">filtered_xs</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'filtered_xs.pkl'</span><span class="p">)</span>
<span class="n">filtered_valid_xs</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'filtered_valid_xs.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="baseline-result">
<a class="anchor" href="#baseline-result" aria-hidden="true"><span class="octicon octicon-link"></span></a>Baseline Result</h2>

<p>Now it’s time to fix <a href="">Out of Domain Data</a> to minimize overfitting.</p>

<h3 id="out-of-domain-data">
<a class="anchor" href="#out-of-domain-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Out of Domain Data</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rf_feat_importance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'cols'</span><span class="p">:</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="s">'imp'</span><span class="p">:</span><span class="n">m</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">}</span>
                       <span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'imp'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_dom</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="n">filtered_valid_xs</span><span class="p">])</span>
<span class="n">is_valid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">filtered_valid_xs</span><span class="p">))</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">rf</span><span class="p">(</span><span class="n">df_dom</span><span class="p">,</span> <span class="n">is_valid</span><span class="p">)</span>
<span class="n">rf_feat_importance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">df_dom</span><span class="p">)[:</span><span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">(</span><span class="s">'timestamp'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="s">'slim_alloy'</span><span class="p">,</span> 
          <span class="s">'international_alloy'</span><span class="p">,</span> <span class="s">'id_machine_article_description'</span><span class="p">,</span>
          <span class="s">'id_idp_user'</span><span class="p">,</span> <span class="s">'last_name'</span><span class="p">,</span> <span class="s">'id_machine'</span><span class="p">,</span> <span class="s">'slim_number'</span><span class="p">,</span>
          <span class="s">'first_name'</span><span class="p">,</span> <span class="s">'code_machine'</span><span class="p">,</span> <span class="s">'description_machine'</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">filtered_valid_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s">'international_alloy'</span><span class="p">,</span> <span class="s">'last_name'</span><span class="p">,</span> <span class="s">'id_machine'</span><span class="p">,</span> <span class="s">'slim_number'</span><span class="p">,</span> <span class="s">'description_machine'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs_final</span> <span class="o">=</span> <span class="n">filtered_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">valid_xs</span> <span class="o">=</span> <span class="n">filtered_valid_xs</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs_final</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_xs</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="n">ovr_rf</span><span class="p">(</span><span class="n">filtered_xs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">pred_prob</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">filtered_valid_xs</span><span class="p">)</span>
<span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">),</span> <span class="n">oob_estimators_avg</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</code></pre></div></div>

<p>Everything ended with less features (<code class="language-plaintext highlighter-rouge">15</code>) and <strong>higher score</strong> both <code class="language-plaintext highlighter-rouge">AUC ROC</code> and <code class="language-plaintext highlighter-rouge">OOB</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">save_pickle</span><span class="p">(</span><span class="s">'final_xs.pkl'</span><span class="p">,</span><span class="n">xs_final</span><span class="p">)</span>
<span class="n">save_pickle</span><span class="p">(</span><span class="s">'final_valid_xs.pkl'</span><span class="p">,</span><span class="n">valid_xs</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="hyperparameter-tuning">
<a class="anchor" href="#hyperparameter-tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hyperparameter Tuning</h3>

<p>Before the game end I’ll try some hypertuning.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs_final</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'final_xs.pkl'</span><span class="p">)</span>
<span class="n">valid_xs</span> <span class="o">=</span> <span class="n">load_pickle</span><span class="p">(</span><span class="s">'final_valid_xs.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span><span class="p">.</span><span class="n">get_params</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span><span class="c1"># Number of trees in random forest
</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)]</span>
<span class="c1"># Number of features to consider at every split
</span><span class="n">max_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'auto'</span><span class="p">,</span> <span class="s">'sqrt'</span><span class="p">]</span>
<span class="c1"># Maximum number of levels in tree
</span><span class="n">max_depth</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">max_depth</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
<span class="c1"># Minimum number of samples required to split a node
</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="c1"># Minimum number of samples required at each leaf node
</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="c1"># Method of selecting samples for training each tree
</span><span class="n">bootstrap</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]</span><span class="c1"># Create the random grid
</span><span class="n">random_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'estimator__n_estimators'</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
               <span class="s">'estimator__max_features'</span><span class="p">:</span> <span class="n">max_features</span><span class="p">,</span>
               <span class="s">'estimator__max_depth'</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
               <span class="s">'estimator__min_samples_split'</span><span class="p">:</span> <span class="n">min_samples_split</span><span class="p">,</span>
               <span class="s">'estimator__min_samples_leaf'</span><span class="p">:</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
               <span class="s">'estimator__bootstrap'</span><span class="p">:</span> <span class="n">bootstrap</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_grid</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="p">.</span><span class="mi">25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf</span><span class="p">.</span><span class="n">get_params</span><span class="p">().</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span> 
<span class="c1"># Use the random grid to search for best hyperparameters
# First create the base model to tune
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">oob_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="c1"># Random search of parameters, using 3 fold cross validation, 
# search across 100 different combinations, and use all available cores
</span><span class="n">rf_random</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span> <span class="n">param_distributions</span> <span class="o">=</span> <span class="n">random_grid</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">sp</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span><span class="c1"># Fit the random search model
</span><span class="n">rf_random</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_final</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_random</span><span class="p">.</span><span class="n">best_params_</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">rf_random</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">pred_prob</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_xs</span><span class="p">)</span>
<span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">),</span> <span class="n">oob_estimators_avg</span><span class="p">(</span><span class="n">best_model</span><span class="p">)</span>
</code></pre></div></div>

<p>Now narrowing the range and trying to gain lil decimals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span><span class="c1"># Number of trees in random forest
</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
<span class="c1"># Number of features to consider at every split
</span><span class="n">max_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'auto'</span><span class="p">,</span> <span class="s">'sqrt'</span><span class="p">]</span>
<span class="c1"># Maximum number of levels in tree
</span><span class="n">max_depth</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="c1"># Minimum number of samples required to split a node
</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="c1"># Minimum number of samples required at each leaf node
</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="c1"># Method of selecting samples for training each tree
</span><span class="n">bootstrap</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="c1"># Create the random grid
</span><span class="n">random_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'estimator__n_estimators'</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
               <span class="s">'estimator__max_features'</span><span class="p">:</span> <span class="n">max_features</span><span class="p">,</span>
               <span class="s">'estimator__max_depth'</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
               <span class="s">'estimator__min_samples_split'</span><span class="p">:</span> <span class="n">min_samples_split</span><span class="p">,</span>
               <span class="s">'estimator__min_samples_leaf'</span><span class="p">:</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
               <span class="s">'estimator__bootstrap'</span><span class="p">:</span> <span class="n">bootstrap</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_grid</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use the random grid to search for best hyperparameters
# First create the base model to tune
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">OneVsRestClassifier</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">oob_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="c1"># Random search of parameters, using 3 fold cross validation, 
# search across 100 different combinations, and use all available cores
</span><span class="n">rf_random</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span> <span class="n">param_distributions</span> <span class="o">=</span> <span class="n">random_grid</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">sp</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span><span class="c1"># Fit the random search model
</span><span class="n">rf_random</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_final</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_random</span><span class="p">.</span><span class="n">best_estimator_</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">narrowed_model</span> <span class="o">=</span> <span class="n">rf_random</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">pred_prob</span> <span class="o">=</span> <span class="n">narrowed_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_xs</span><span class="p">)</span>
<span class="n">avg_roc_auc</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">),</span> <span class="n">oob_estimators_avg</span><span class="p">(</span><span class="n">narrowed_model</span><span class="p">)</span>
</code></pre></div></div>

<p>From <code class="language-plaintext highlighter-rouge">94%</code> to almost <code class="language-plaintext highlighter-rouge">94.7%</code> is the final score. OOB stable on <code class="language-plaintext highlighter-rouge">95.3%</code> range.</p>

<h2 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<p>Miss-classifying the tare weight (Aluminium scarp box) is expensive causing <strong>damage to the company (less revenue) and environment (re-melting Aluminium)</strong>.</p>

<p><strong>Scoring a <code class="language-plaintext highlighter-rouge">94.7%</code> of predicting right is a great baseline. Sure less scraps will be wasted.</strong></p>

<h2 id="further-work">
<a class="anchor" href="#further-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Further Work</h2>

<ol>
  <li>Develop service which host the model.</li>
  <li>How reacts the model if I remove duplicated rows? Do it.</li>
  <li>I know the dataset is imbalanced. Implement it.</li>
  <li>Compare the result with <a href="https://arxiv.org/pdf/2207.08815.pdf">deep learning tabular model</a>.</li>
  <li>Compare the result with XGBoost model.</li>
  <li>Using same method to classify Aluminium alloys.</li>
</ol>

  </div><a class="u-url" href="/bottoni/project/random/forest/multi/class/classification/2022/11/17/the-random-forest-guy.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/bottoni/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/bottoni/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/bottoni/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Open notes</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/B8ni" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/bottoni/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/bot_fra" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/bottoni/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
